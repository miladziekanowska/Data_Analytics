{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcrbcrTblo+b3a9Yc02qUr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miladziekanowska/Data_Analytics/blob/main/Pandas_Data_Cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning data in Pandas DataFrame\n",
        "Data cleaning is one of the tedious parts of work as a Data Analyst or Data Scientist, but it is one of the most important part of the the field - well prepared data can give us more insight and therefore allow us to make better informed decisions and train our models properly.\n",
        "\n",
        "This notebook takes up quite a lot of examples of nessesary data cleaning with a few solutions, with the problems listed here:\n",
        "1. Correcting the data type to our needs (konwersja danych w kolumnach)\n",
        "2. Splitting the date and string columns (rozdzielanie danych z jednej kolumny na wiele)\n",
        "3. Handling missing data and NaN valeus (obsługa brakujących wartości)\n",
        "4. Detecting and dealing with outliers (wykrywanie i radzenie sobie z brakującymi danymi)\n",
        "5. Data Standarization (standaryzacja danych)\n",
        "6. Data Discreditation (dyskredytacja danych)\n",
        "7. Data Normalization\n",
        "8. Log Normalize (transformacja logarytmiczna)\n",
        "9. One-hot encoding (czyli zamiast czarne - białe robimy czarne - nie czarne)\n",
        "10. Data scaling (skalowanie)\n",
        "11. Profiling (to fajne z tworzeniem html z analizką)\n",
        "\n",
        "\n",
        "Okay, let's get to work with the imports and first DataFrame."
      ],
      "metadata": {
        "id": "qYXxJRY1YDAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt # for data visualization\n",
        "import seaborn as sns # for statistical data visualization\n",
        "import pylab \n",
        "import scipy.stats as stats\n",
        "import datetime"
      ],
      "metadata": {
        "id": "eRGXaZHIdRwB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We won't be doing any visualisations in this notebook I think, but it's a good practice to be prepared here. "
      ],
      "metadata": {
        "id": "ZJfu2-bjdaZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correcting the columns\n",
        "Before we jump in to any other cleaning and changes with our data, it is best to get to know it a little bit better. "
      ],
      "metadata": {
        "id": "lqXpFviohl6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling missing values \n",
        "There are a few types of missing values in a DataFrame, which might cause some issues with the outcome and modeling.  \n",
        "These values could be put in a following list:  \n",
        "`falsy_values = (0, False, None, '', [], {})`  \n",
        "Don't get it wrong, 0 within a numeric column often won't be a missing data - it is important to know the context of the column before we start to clean it. With numeric data, if 0 is and outlier, it still gives us some information and might not be a mistake - it could mean that, for example, a store was closed that day, therefore the total retails is 0. Even more so, if 0 is within the range, then we don't touch it, as this most likely a totally valid data, especially if there are not many of it. However, if we get a 0 within non-numeric (and already tranfo\n"
      ],
      "metadata": {
        "id": "6mRHuNpseZLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(np.random.randn(6, 4), \n",
        "                  index=dates, \n",
        "                  columns=list('ABCD'))\n",
        "df['D'] = -5\n",
        "df['E'] = [np.nan, -1,-2,-3, -4, -5]\n",
        "df['F'] = [1,2, np.nan, np.nan,np.nan, np.nan]\n",
        "df"
      ],
      "metadata": {
        "id": "FVVQJQ1neh9H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}