{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMI6wzkYz49gkgAQa3Y0VIX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miladziekanowska/Data_Analytics/blob/main/Pandas_basics_and_Dataframe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas\n",
        "Pandas stands for *Python Data Analytics* and is one of the basic tools we will use for data analytics and data science. It is build on top of Numpy, therefore whenever we start working on a project that involves Pandas, we need to import Numpy as well.\n",
        "\n",
        "Pandas is mainly used for easy computing with:\n",
        "- tabular data;\n",
        "- time series;\n",
        "- matrices;\n",
        "- records and statistics.\n"
      ],
      "metadata": {
        "id": "MDGOHjeFogPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "aOCwfddeKLV-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data structures in Pandas\n",
        "In Pandas we can differenciate two types of pandas-specific data structures. These would be:\n",
        "- Series - `pd.Series`, which are farely similar to lists, but optimized. These will often be our columns, in:\n",
        "- DataFrame - `pd.DataFrame`, which are presented as tabular data, similar to spreadsheets. The columns will contain\n"
      ],
      "metadata": {
        "id": "ZsqyeNurKOjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = pd.Series([25, 73, 94, 20]) # example of a Series\n",
        "scores"
      ],
      "metadata": {
        "id": "auQP7P3MP1rK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(scores) # using type we can check what we created"
      ],
      "metadata": {
        "id": "-2_7PgnGP-JT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'A' : [1, 2, 3],\n",
        "                   'B' : [4, 5, 6]})\n",
        "df # if we are working on one dataframe at a time, it's common to call it df and best practice is to include 'df' in the name always"
      ],
      "metadata": {
        "id": "-ixAmlwjQryC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df)"
      ],
      "metadata": {
        "id": "9EnVdEfYQtCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a random data frame and see what we can do with is. Most often we will create dfs from files (csv, json, xml, etc.)."
      ],
      "metadata": {
        "id": "ewobrIe3Qvf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame is always two dimentional, just like a matrix. \n",
        "# When we are creating one from scrach, shape does not have to be specify in every column, just like in columns 'A' and 'F'\n",
        "df = pd.DataFrame({\n",
        "                    'A': 1.,\n",
        "                    'B': pd.Timestamp('20130102'),\n",
        "                    'C': pd.Series(1, index=list(range(4)), dtype='float32'),\n",
        "                    'D': np.array([3] * 4, dtype='int32'),\n",
        "                    'E': pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
        "                    'F': 'foo',\n",
        "                    'G' : [False, True,True,False]\n",
        "                   })\n",
        "df"
      ],
      "metadata": {
        "id": "X5mGhvpORmpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrames are a special type of class in Pandas. Therefore they have some special methods within them and we do not need to call for functions as much.\n",
        "df.info() # with this method we are getting information about all the columns (Series) in our DataFrame"
      ],
      "metadata": {
        "id": "vwGsE_4-SRWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `df.info()` will give us information on all columns and their data types, as well as the quantity of non-null (or, in numpy and pandas, not NaN) values. \n",
        "\n",
        "This is very useful, when we are starting our analysis, for a number of reasons:\n",
        "1. Null/NaN values might throw off our analysis;\n",
        "2. If a column contains many Null/NaN values, perhaps we cannot use it for our analysis or need to contact our client/data bank, we might also think of a way to fill the Nulls/NaNs;\n",
        "3. With some data types we need to work differently;\n",
        "4. With non-numeric data types we might want to split them, take somethin out, etc.;\n",
        "5. For more advanced analysis and ML, we might want to transform the non-numeric data into numeric data."
      ],
      "metadata": {
        "id": "QLLQ1XbzSwpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape # same as with numpy, this will show us shape"
      ],
      "metadata": {
        "id": "2IevGzWUYxcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.size # and size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_gJTpNaY4U1",
        "outputId": "f1c12e5e-2c63-4f0b-cff6-4476fb77e94d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns # this will show us all the column names"
      ],
      "metadata": {
        "id": "SAV0JCiJYhRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.index # and this will show us available index"
      ],
      "metadata": {
        "id": "dNHL8jfgZOpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.values # and values"
      ],
      "metadata": {
        "id": "PqGY168zZVuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing a cvs file\n",
        "Let's work on a mock-life example of a data frame. First for that, we need to import the file. With virtual environments like Google Collab or Jupyter Notebook we need to remember to provide the right path to the file then we are importing (as always, but it's slightly different)."
      ],
      "metadata": {
        "id": "XFPEaQ__U9SB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df = pd.read_csv('dane_sprzedaz.csv', sep=',', encoding='utf-8')\n",
        "sales_df"
      ],
      "metadata": {
        "id": "cv-20ZQKVIVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see how the data looks in here\n",
        "sales_df.info()"
      ],
      "metadata": {
        "id": "8y6RqutaV2r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, in the column named 'SPRZ_NETTO' we have two NaN values, but we will get to that later.\n",
        "\n",
        "Let's try some of the methods we can use on a DataFrame."
      ],
      "metadata": {
        "id": "W8Z_F886V8Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# There are methods that will show us a given number of rows in a few manners\n",
        "sales_df.head(5) # .head() gives us the first n rows"
      ],
      "metadata": {
        "id": "976szowlWMtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df.tail(5) # .tail() will give us the last n rows"
      ],
      "metadata": {
        "id": "qlizML-NWhmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df.sample(5) # .sample () will give us random n rows from the DataFrame. This is good to have a glimse, but not best practice for sampling"
      ],
      "metadata": {
        "id": "aZOz30SnWp6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indexing and slicing \n",
        "Indexing and slicing in DataFrames is a mix of Numpy Matrices and Dictionaries. The way is similar and the indexes we call are usually in columns (sometimes with some conditions as filtering). \n"
      ],
      "metadata": {
        "id": "--fkYO3nWzaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df.SKL_ID # this way we can get the whole column as a Series\n",
        "#OR sales_df(['SKL_ID'])"
      ],
      "metadata": {
        "id": "cchBEFilX-ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df[['DZIEN_DATA', 'TOW_ID']] #this way we can call for more than one column"
      ],
      "metadata": {
        "id": "HJaAVTVwYBiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### .iloc and .loc\n",
        "These two methods allow us to slice through the DataFrame in two different ways. Both are useful (.iloc is more often used) for different tasks.\n",
        "\n",
        "`.iloc` will look at the index given the position in the DataFrame;\n",
        "\n",
        "`.loc` will look at the index as the given position."
      ],
      "metadata": {
        "id": "ONh51BqLZev1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for this example let's use a new dataframe to better see the difference\n",
        "b = pd.Series(np.round(np.random.uniform(0,1,10),2))\n",
        "i = np.r_[0:10]\n",
        "np.random.shuffle(i)\n",
        "b.index = i\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY5nnQMja6Z8",
        "outputId": "903101ef-c4b9-4849-d24d-523961348fec"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8    0.27\n",
              "5    0.32\n",
              "1    0.25\n",
              "0    0.07\n",
              "4    0.52\n",
              "9    0.24\n",
              "3    0.01\n",
              "6    0.47\n",
              "2    0.61\n",
              "7    0.87\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.iloc[2] # it will give us the third value in the overall table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrK8t2kDbKcR",
        "outputId": "f5ab85f0-6979-4e9b-c58a-3ac87e334be3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.loc[2] # this will give us the value with the index '2'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ8zIy2CbT1c",
        "outputId": "520e131d-6a51-45c6-df20-5f53d1704644"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.61"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OavHLZbjbc7q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}